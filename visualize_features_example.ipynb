{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "-- Configuration\n",
    "torch.manualSeed(1)\n",
    "torch.setdefaulttensortype(\"torch.FloatTensor\")\n",
    "package.path = package.path .. \";models/?.lua\"\n",
    "require \"nn\"\n",
    "require \"image\"\n",
    "require \"visualize_features_utils\"\n",
    "require \"SpatialReplicatePadding\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "-- Initialize OverFeat model\n",
    "overfeat_factory = require \"OverFeatFactory\"\n",
    "overfeat_params = {type = \"small\", pretrained = true, weights_path = \"models/net_weight_0\"}\n",
    "conv_net, softmax_net = overfeat_factory.create(overfeat_params)\n",
    "-- Remove non-convolutional layers\n",
    "for i=1,5 do conv_net:remove() end\n",
    "-- \"Fix\" convolutional layers\n",
    "new_conv_net = nn.Sequential()\n",
    "for i,m in pairs(conv_net.modules) do\n",
    "    -- Check layer\n",
    "    if torch.typename(m) == \"nn.SpatialConvolutionMM\" then\n",
    "        -- Change stride\n",
    "        m.dH = 1\n",
    "        m.dW = 1\n",
    "        -- Remove padding\n",
    "        m.padH = 0\n",
    "        m.padW = 0\n",
    "        -- Add replicate-padding layer to conv net\n",
    "        new_conv_net:add(nn.SpatialReplicatePadding((m.kW-1)/2, (m.kH-1)/2))\n",
    "    elseif torch.typename(m) == \"nn.SpatialMaxPooling\" then\n",
    "        -- Make the module know some unpoolers will be attached\n",
    "        -- (it won't set iwidth and iheight during forward() otherwise)\n",
    "        local dummy = nn.SpatialMaxUnpooling(m)\n",
    "    end\n",
    "    -- Add module\n",
    "    new_conv_net:add(m)\n",
    "end\n",
    "conv_net = new_conv_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "-- Test image (bee)\n",
    "dim = 231\n",
    "img = image.load(\"bee.jpg\"):mul(255)\n",
    "img = image.scale(img, \"^\" .. dim)\n",
    "img = image.crop(img, \"c\", dim, dim)\n",
    "img = img:floor()\n",
    "orig_img = img:clone()\n",
    "img:add(-118.380948):div(61.896913)\n",
    "itorch.image(orig_img)\n",
    "-- Forward input image\n",
    "conv_net:forward(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "-- Show maps\n",
    "resize = 300\n",
    "-- Interesting layers\n",
    "observed_layers = {4, 8, 11, 14, 18} --, 6, 8, 10, 13} -- 5\n",
    "-- Number of neurons to show\n",
    "limits = {6, 6, 6, 6, 6}\n",
    "-- Configure map overlap\n",
    "allow_map_overlap = true\n",
    "overlap_margin = 5\n",
    "-- Process all layers\n",
    "for target_layer_idx,target_layer in pairs(observed_layers) do\n",
    "    print(\"Layer \" .. target_layer_idx .. \" (\" .. target_layer .. \")\")\n",
    "    -- Build reconstruction network\n",
    "    local deconv_net = buildReconstructionNet(conv_net, target_layer)\n",
    "    -- Select layer and map\n",
    "    target_map = nil\n",
    "    -- Get active neurons\n",
    "    local active_values, active_coords = getActiveNeurons(conv_net, target_layer, target_map)\n",
    "    -- Filter neurons\n",
    "    -- This may take a while if overlap is not allowed and there are not enough non-overlapping\n",
    "    local n = limits[target_layer_idx]\n",
    "    active_values, active_coords = filterNeurons(active_values, active_coords, n, overlap_margin, allow_map_overlap)\n",
    "    -- Compute reconstruction inputs\n",
    "    rec_inputs = getReconstructionInput(active_values, active_coords, conv_net, target_layer, target_map)\n",
    "    -- Compute reconstruction outputs\n",
    "    rec_outputs = {}\n",
    "    orig_outputs = {}\n",
    "    crops = {}\n",
    "    for i=1,#rec_inputs do\n",
    "        -- Reconstruct\n",
    "        rec_output = deconv_net:forward(rec_inputs[i])\n",
    "        -- Compute activity mask\n",
    "        local activity_mask = localizeActivity(rec_output, {activity_thr = 0.0001})\n",
    "        -- Compute crop points\n",
    "        local crop = getMaskCoords(activity_mask)\n",
    "        -- Crop reconstruction and scale\n",
    "        rec_output = image.crop(rec_output, unpack(crop))\n",
    "        rec_output = image.scale(rec_output, resize, resize)\n",
    "        -- Crop original and scale\n",
    "        local orig_output = image.crop(orig_img, unpack(crop))\n",
    "        orig_output = image.scale(orig_output, resize, resize)\n",
    "        -- Add to tables\n",
    "        table.insert(rec_outputs, rec_output)\n",
    "        table.insert(orig_outputs, orig_output)\n",
    "        table.insert(crops, crop)\n",
    "        collectgarbage()\n",
    "    end\n",
    "    -- Highlight active neurons in original images\n",
    "    draw_crops = orig_img:clone()\n",
    "    for _,crop in pairs(crops) do\n",
    "        -- Draw rectangle\n",
    "        drawRectangle(draw_crops, {crop[1], crop[2]}, {crop[3], crop[4]}, torch.Tensor({255,0,0}))\n",
    "    end\n",
    "    itorch.image(draw_crops, {min = 0, max = 255})\n",
    "    -- Show reconstruction besides original patches\n",
    "    rec_outputs_img = image.toDisplayTensor({input = rec_outputs, padding = 2})\n",
    "    orig_outputs_img = image.toDisplayTensor({input = orig_outputs, padding = 2, min = 0, max = 255})\n",
    "    itorch.image(torch.cat(rec_outputs_img, orig_outputs_img, 3))\n",
    "    -- Fixes some problems on my machine which caused a bad ordering between prints and itorch.image() calls\n",
    "    -- Uncomment if you have the sys package (and add a \"require\")\n",
    "    --sys.sleep(3) \n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iTorch",
   "language": "lua",
   "name": "itorch"
  },
  "language_info": {
   "name": "lua",
   "version": "20100"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
